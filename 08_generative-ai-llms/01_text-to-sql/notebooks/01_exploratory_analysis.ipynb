{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-to-SQL: Exploratory Analysis\n",
    "\n",
    "This notebook explores the sample e-commerce database and demonstrates basic Text-to-SQL functionality.\n",
    "\n",
    "## Objectives\n",
    "1. Explore the database schema and relationships\n",
    "2. Analyze sample data distribution\n",
    "3. Test basic natural language queries\n",
    "4. Understand query complexity patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(str(Path('../src').resolve()))\n",
    "\n",
    "from schema_manager import SchemaManager\n",
    "from query_generator import TextToSQLGenerator, QueryResult\n",
    "from query_validator import QueryValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Database Schema Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize database connection\n",
    "db_path = \"../data/sample_database.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Initialize schema manager\n",
    "schema_manager = SchemaManager(db_path)\n",
    "schema_info = schema_manager.get_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all tables\n",
    "print(\"Database Tables:\")\n",
    "print(\"=\" * 50)\n",
    "for table in schema_info.tables:\n",
    "    print(f\"\\n{table.name}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Columns: {', '.join([f'{col.name} ({col.type})' for col in table.columns])}\")\n",
    "    if table.primary_key:\n",
    "        print(f\"Primary Key: {table.primary_key}\")\n",
    "    if table.foreign_keys:\n",
    "        print(f\"Foreign Keys: {table.foreign_keys}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize schema in CREATE TABLE format\n",
    "schema_str = schema_manager.format_schema(format_type=\"create_table\")\n",
    "print(\"\\nDatabase Schema (CREATE TABLE format):\")\n",
    "print(\"=\" * 80)\n",
    "print(schema_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get row counts for each table\n",
    "print(\"Table Row Counts:\")\n",
    "print(\"=\" * 50)\n",
    "for table in schema_info.tables:\n",
    "    query = f\"SELECT COUNT(*) as count FROM {table.name}\"\n",
    "    count = pd.read_sql_query(query, conn).iloc[0]['count']\n",
    "    print(f\"{table.name}: {count} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore customers table\n",
    "print(\"\\nCustomers Sample:\")\n",
    "customers_df = pd.read_sql_query(\"SELECT * FROM customers LIMIT 5\", conn)\n",
    "display(customers_df)\n",
    "\n",
    "print(\"\\nCustomer Registration Over Time:\")\n",
    "registration_stats = pd.read_sql_query(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "        DATE(registration_date) as date,\n",
    "        COUNT(*) as new_customers\n",
    "    FROM customers\n",
    "    GROUP BY DATE(registration_date)\n",
    "    ORDER BY date\n",
    "    \"\"\",\n",
    "    conn\n",
    ")\n",
    "display(registration_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore products table\n",
    "print(\"Products by Category:\")\n",
    "products_by_category = pd.read_sql_query(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "        category,\n",
    "        COUNT(*) as product_count,\n",
    "        ROUND(AVG(price), 2) as avg_price,\n",
    "        ROUND(AVG(stock_quantity), 2) as avg_stock\n",
    "    FROM products\n",
    "    GROUP BY category\n",
    "    ORDER BY product_count DESC\n",
    "    \"\"\",\n",
    "    conn\n",
    ")\n",
    "display(products_by_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore orders and revenue\n",
    "print(\"Order Statistics:\")\n",
    "order_stats = pd.read_sql_query(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "        status,\n",
    "        COUNT(*) as order_count,\n",
    "        ROUND(AVG(total_amount), 2) as avg_order_value,\n",
    "        ROUND(SUM(total_amount), 2) as total_revenue\n",
    "    FROM orders\n",
    "    GROUP BY status\n",
    "    \"\"\",\n",
    "    conn\n",
    ")\n",
    "display(order_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze reviews\n",
    "print(\"Review Distribution:\")\n",
    "review_dist = pd.read_sql_query(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "        rating,\n",
    "        COUNT(*) as review_count,\n",
    "        ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM reviews), 2) as percentage\n",
    "    FROM reviews\n",
    "    GROUP BY rating\n",
    "    ORDER BY rating DESC\n",
    "    \"\"\",\n",
    "    conn\n",
    ")\n",
    "display(review_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Natural Language Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Text-to-SQL generator (requires API key)\n",
    "# Uncomment and add your API key to test\n",
    "# import os\n",
    "# os.environ['OPENAI_API_KEY'] = 'your-key-here'\n",
    "# generator = TextToSQLGenerator(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test queries\n",
    "with open('../data/test_queries.json', 'r') as f:\n",
    "    test_queries = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(test_queries)} test queries\\n\")\n",
    "\n",
    "# Show query categories\n",
    "categories = {}\n",
    "for query in test_queries:\n",
    "    cat = query['category']\n",
    "    categories[cat] = categories.get(cat, 0) + 1\n",
    "\n",
    "print(\"Query Categories:\")\n",
    "for cat, count in sorted(categories.items()):\n",
    "    print(f\"  {cat}: {count} queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample queries from each complexity level\n",
    "print(\"\\nSample Queries by Complexity:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for complexity in ['simple', 'medium', 'complex']:\n",
    "    matching = [q for q in test_queries if q['complexity'] == complexity]\n",
    "    if matching:\n",
    "        sample = matching[0]\n",
    "        print(f\"\\n{complexity.upper()} Query:\")\n",
    "        print(f\"Question: {sample['question']}\")\n",
    "        print(f\"Expected SQL: {sample['expected_sql']}\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Manually execute a test query to verify results\n",
    "example_query = test_queries[0]\n",
    "print(f\"Executing: {example_query['question']}\")\n",
    "print(f\"SQL: {example_query['expected_sql']}\\n\")\n",
    "\n",
    "result_df = pd.read_sql_query(example_query['expected_sql'], conn)\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query Complexity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze query patterns in test set\n",
    "import re\n",
    "\n",
    "def analyze_query_complexity(sql: str) -> dict:\n",
    "    \"\"\"Analyze SQL query complexity.\"\"\"\n",
    "    sql_upper = sql.upper()\n",
    "    return {\n",
    "        'has_join': 'JOIN' in sql_upper,\n",
    "        'has_subquery': '(' in sql and 'SELECT' in sql_upper,\n",
    "        'has_aggregate': any(func in sql_upper for func in ['COUNT', 'SUM', 'AVG', 'MAX', 'MIN']),\n",
    "        'has_group_by': 'GROUP BY' in sql_upper,\n",
    "        'has_order_by': 'ORDER BY' in sql_upper,\n",
    "        'has_where': 'WHERE' in sql_upper,\n",
    "        'num_tables': len(re.findall(r'FROM\\s+(\\w+)', sql_upper)) + len(re.findall(r'JOIN\\s+(\\w+)', sql_upper)),\n",
    "    }\n",
    "\n",
    "# Analyze all test queries\n",
    "complexity_stats = []\n",
    "for query in test_queries:\n",
    "    stats = analyze_query_complexity(query['expected_sql'])\n",
    "    stats['complexity'] = query['complexity']\n",
    "    complexity_stats.append(stats)\n",
    "\n",
    "complexity_df = pd.DataFrame(complexity_stats)\n",
    "print(\"\\nQuery Pattern Distribution:\")\n",
    "print(\"=\" * 80)\n",
    "print(complexity_df.groupby('complexity').mean().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Schema Relevance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test table relevance identification\n",
    "test_questions = [\n",
    "    \"Show me all customers from California\",\n",
    "    \"What are the top selling products?\",\n",
    "    \"Which customers have never placed an order?\",\n",
    "    \"What's the average order value by customer city?\"\n",
    "]\n",
    "\n",
    "print(\"Table Relevance Detection:\")\n",
    "print(\"=\" * 80)\n",
    "for question in test_questions:\n",
    "    relevant_tables = schema_manager.identify_relevant_tables(question)\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    print(f\"Relevant tables: {relevant_tables}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary and Insights\n",
    "\n",
    "### Key Findings:\n",
    "1. **Database Structure**: 5 tables with clear relationships (customers, products, orders, order_items, reviews)\n",
    "2. **Data Volume**: Small sample dataset suitable for testing and demo\n",
    "3. **Query Complexity**: Test queries range from simple filters to complex multi-table joins\n",
    "4. **Common Patterns**: \n",
    "   - Customer analysis queries\n",
    "   - Product performance queries\n",
    "   - Order and revenue analytics\n",
    "   - Review sentiment analysis\n",
    "\n",
    "### Next Steps:\n",
    "- Optimize prompts for different query complexities (see notebook 02)\n",
    "- Evaluate model performance on test queries (see notebook 03)\n",
    "- Test edge cases and error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
